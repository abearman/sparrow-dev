## Design Decisions

In this document, we present the design rationale for our exploration strategy as well as some key design decisions.

Upon receiving the project prompt from SAP, we quickly decided to focus on the enabling technology of autonomous drone navigation in GPS-denied environments as our main product. We were considering warehouse inventory management as our first application due to the simplicity of the environment, but later decided that drones would provide more value in environments with uneven terrain that terrestrial robots would not be able to traverse. To that end, we decided to shift our focus to another application: search and rescue (SAR) operations. Unlike warehouse inventory management, SAR would entail exploration of a previously unknown space.

Early on in our development process, we had multiple discussions about how we would perform the localization and potentially globalization needed for indoor drone navigation. We considered three key options: stereo vision using external cameras, onboard sonar and lidar sensors, and the Google Tango. Using triangulation using external cameras set up around a space initially seemed like a feasible option, but it soon became clear that this prevents much of the flexibility and portability we desired in our product. We then considered sonar and lidar, common means of onboard sensors to perform collision avoidance and to understand local space; this mechanism would give us the portability we desired and would allow us to get a 360 degree field of view. However, we ultimately decided to use the Google Tango. Even though it would only provide us with an 180 degree field of view, we felt that for our initial prototype, it would behoove us to use a preexisting technology that was specifically built with motion tracking, depth sensing, and localization capabilities.

Our initial method of performing the indoor drone navigation was to use the proportional-integral-derivative (PID) control mechanism; this control loop feedback mechanism continuously calculates error value as the difference between a desired setpoint and a measured process variable. Although this method initially seemed promising, PID tuning did not prove to be as successful of a method as initially imagined. Thus, our next step was to modify the drone's firmware itself and to re-compile the Arducopter code while replacing all the GPS calls with Tango local coordinate calls.

While the indoor autonomous navigation component of our project was in process, we made the decision to simultaneously build out an iPad application so that users would be able to gain value from our product. Initially, we had made the conscious decision to focus on the core technology of indoor autonomous navigation. However, as we realized that this complex problem necessitated far more than our allotted time to work on it, we decided that we could reduce idle cycles by actually building out the iPad technology for our users.

For this application, we decided to include some SAR-specific items. After several meetings with former military officers who were experienced in SAR operations, we ultimately decided on three core SAR-specific features in our app to provide value to our users: (1) the ability to fly common predetermined SAR paths from an LKP, (2) the ability to drop pins on a map to be able to track when people or items of interest are found, and (3) a video/photo feed to be able to provide the user with real-time feedback on the drone's discovery of an unknown space. From our breakathon with Cargi, we garnered some valuable feedback, particularly with regard to our interface to be able to control the drone in real-time from an application, which we are using to tweak our user interface to make it more intuitive for users.
